{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXa7TLrrmKOo"
   },
   "source": [
    "## Deep Learning Course Project - Gesture Recognition\n",
    "\n",
    "### Problem Statement\n",
    "Imagine you are working as a data scientist at a home electronics company which manufactures state of the art smart televisions. You want to develop a cool feature in the smart-TV that can recognise five different gestures performed by the user which will help users control the TV without using a remote.\n",
    "\n",
    "The gestures are continuously monitored by the webcam mounted on the TV. Each gesture corresponds to a specific command:\n",
    " \n",
    "| Gesture | Corresponding Action |\n",
    "| --- | --- | \n",
    "| Thumbs Up | Increase the volume. |\n",
    "| Thumbs Down | Decrease the volume. |\n",
    "| Left Swipe | 'Jump' backwards 10 seconds. |\n",
    "| Right Swipe | 'Jump' forward 10 seconds. |\n",
    "| Stop | Pause the movie. |\n",
    "\n",
    "Each video is a sequence of 30 frames (or images).\n",
    "\n",
    "### Objectives:\n",
    "1. **Generator**:  To write code for the generator which takes a batch of videos \n",
    "\n",
    "2. **Model**: to Develop a model that is able to train with number of parameters and with better accuracy. \n",
    "\n",
    "3. **Write up**: to write detailed procedure followed in choosing the final model, highlighting the reasons and metrics taken into consideration to modify and experiment to arrive at the final model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "I1WwqcNQmKOu"
   },
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import abc\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tlO6tCL4mKOv",
    "outputId": "ce7ec667-af13-4686-f3c6-b9311dbb4971"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.framework.random_seed.set_seed(seed)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(30)   #We set the random seed so that the results don't vary drastically.\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DLuvP04lmKOx"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3ZFKPawumKOy"
   },
   "outputs": [],
   "source": [
    "# importing some other libraries which will be needed for model building.\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nLdbpuhfmKOz"
   },
   "outputs": [],
   "source": [
    "# renaming the project folder\n",
    "project_folder='/datasets/Project_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfK8yFbTmKOz"
   },
   "source": [
    "## Function to Plot the training /validation accuracy/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "C014lD5tmKO0"
   },
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(history.history['loss'])   \n",
    "    axes[0].plot(history.history['val_loss'])\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "\n",
    "    axes[1].plot(history.history['categorical_accuracy'])   \n",
    "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
    "    axes[1].legend(['train_categorical_accuracy','val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XP6q428omKO1"
   },
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. \n",
    "we are going to \n",
    "1. preprocess the two dimentional images \n",
    "2. create a batch of video frames. \n",
    "3. experiment with `number of frames per video`,`hieght of image`,`width of image`, `normalization` to get good accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5J8wVhoimKO1"
   },
   "outputs": [],
   "source": [
    "class ModelBuilder(metaclass= abc.ABCMeta):\n",
    "    \n",
    "    # initialisng the path where project data resides\n",
    "    def initialize_path(self,project_folder):\n",
    "        self.train_doc = np.random.permutation(open(project_folder + '/' + 'train.csv').readlines())\n",
    "        self.val_doc = np.random.permutation(open(project_folder + '/' + 'val.csv').readlines())\n",
    "        self.train_path = project_folder + '/' + 'train'\n",
    "        self.val_path =  project_folder + '/' + 'val'\n",
    "        self.num_train_sequences = len(self.train_doc)\n",
    "        self.num_val_sequences = len(self.val_doc)\n",
    "        \n",
    "    # initialising the image properties    \n",
    "    def initialize_image_properties(self,image_height=100,image_width=100):\n",
    "        self.image_height=image_height\n",
    "        self.image_width=image_width\n",
    "        self.channels=3\n",
    "        self.num_classes=5\n",
    "        self.total_frames=30\n",
    "        \n",
    "    # initialising the batch size, frames to sample and the no. of epochs\n",
    "    def initialize_hyperparams(self,frames_to_sample=30,batch_size=20,num_epochs=20):\n",
    "        self.frames_to_sample=frames_to_sample\n",
    "        self.batch_size=batch_size\n",
    "        self.num_epochs=num_epochs\n",
    "        \n",
    "    # MOST IMPORTANT PART HERE - The generator function        \n",
    "    def generator(self,source_path, folder_list, augment=False):\n",
    "        img_idx = np.round(np.linspace(0,self.total_frames-1,self.frames_to_sample)).astype(int)\n",
    "        batch_size=self.batch_size\n",
    "        #print(\"\\n ========================3rd line of generator============ \\n\")\n",
    "        \n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            #print(\"\\n ========================inside while loop============ \\n\")\n",
    "            num_batches = len(t)//batch_size\n",
    "             \n",
    "            for batch in range(num_batches): \n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,batch,batch_size,img_idx,augment)\n",
    "                #print(\"\\n ========================inside for batch ============ \\n\")\n",
    "                yield batch_data, batch_labels \n",
    "\n",
    "            remaining_seq=len(t)%batch_size\n",
    "            #print(\"\\n remaining_seq.......................>\\n \",remaining_seq)\n",
    "            \n",
    "            if (remaining_seq != 0):\n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,num_batches,batch_size,img_idx,augment,remaining_seq)\n",
    "                #print(\"\\n ========================inside if of remaining seq ============ \\n\")\n",
    "                yield batch_data, batch_labels \n",
    "    \n",
    "    \n",
    "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
    "        #print(\"\\n ========================inside one_batch_data ============ \\n\")\n",
    "        \n",
    "        seq_len = remaining_seq if remaining_seq else batch_size\n",
    "    \n",
    "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
    "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
    "           \n",
    "        if (augment):\n",
    "              batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
    "\n",
    "        \n",
    "        for folder in range(seq_len): \n",
    "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
    "            #print(\"\\n ========================inside for folder ============ \\n\")\n",
    "            \n",
    "            for idx,item in enumerate(img_idx):\n",
    "                #print(\"\\n ========================inside idx,item enumerate for loop ============ \\n\")\n",
    "                \n",
    "                #performing image reading \n",
    "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                               \n",
    "                # performing image resizeing\n",
    "                image_resized=resize(image,(self.image_height,self.image_width,3))\n",
    "                            \n",
    "                #normalizing the images in all three images\n",
    "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "                       \n",
    "                if (augment):\n",
    "                    #print(\"\\n ========================3rd line of generator============ \\n\")\n",
    "                    shifted = cv2.warpAffine(image,\n",
    "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
    "                                            (image.shape[1], image.shape[0]))\n",
    "                    \n",
    "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
    "                   \n",
    "                    # cropping the images to have the targeted gestures and remove the noise from the images.\n",
    "                    cropped=shifted[x0:x1,y0:y1,:]\n",
    "                    \n",
    "                    image_resized=resize(cropped,(self.image_height,self.image_width,3))\n",
    "                            \n",
    "                    batch_data_aug[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                    batch_data_aug[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                    batch_data_aug[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "                             \n",
    "            \n",
    "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "         \n",
    "        if (augment):\n",
    "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
    "            batch_labels=np.concatenate([batch_labels,batch_labels]) \n",
    "        return(batch_data,batch_labels)\n",
    "        \n",
    "    \n",
    "    def train_model(self, model, augment_data=False):\n",
    "        #print(\"\\n ========================inside train model ============ \\n\")\n",
    "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
    "        val_generator = self.generator(self.val_path, self.val_doc)\n",
    "\n",
    "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "        \n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
    "        \n",
    "        earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
    "        callbacks_list = [checkpoint, LR, earlystop]\n",
    "\n",
    "        if (self.num_train_sequences%self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
    "        else:\n",
    "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
    "\n",
    "        if (self.num_val_sequences%self.batch_size) == 0:\n",
    "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
    "        else:\n",
    "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
    "    \n",
    "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
    "                            callbacks=callbacks_list, validation_data=val_generator, \n",
    "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "        #print(\"\\n ========================inside history=model.fit============ \\n\")\n",
    "        return history\n",
    "\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def define_model(self):\n",
    "        #print(\"\\n ========================inside define_model============ \\n\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvEDJdRJmKO-"
   },
   "source": [
    "## Model\n",
    "Building the model using different functionalities that Keras provides.\n",
    "\n",
    "1. `Conv3D` and `MaxPooling3D` are used for `3D convolution model`. \n",
    "2.  and `TimeDistributed` is used while building a `Conv2D + RNN model`. \n",
    "3.  and the last layer is the `softmax`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGodN2ddmKO_"
   },
   "source": [
    "## Model 1\n",
    "### Base Model - Batch Size = 40 and No. of Epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "O7ssw9fpmKPA"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D1(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        #optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99SOSLj8mKPA",
    "outputId": "3bbc5116-7899-4745-ca4b-9aa70f4b3117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 20, 160, 160, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 20, 160, 160, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 20, 160, 160, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 10, 80, 80, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 10, 80, 80, 32)    13856     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10, 80, 80, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 80, 80, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 5, 40, 40, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 5, 40, 40, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5, 40, 40, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 5, 40, 40, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 20, 20, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 2, 20, 20, 128)    221312    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 20, 20, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 20, 20, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 1, 10, 10, 128)    0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                819264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 1,117,061\n",
      "Trainable params: 1,116,325\n",
      "Non-trainable params: 736\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_path(project_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=20,batch_size=40,num_epochs=15)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "conv_3d1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUxP9XG0mKPB",
    "outputId": "a301770b-b6e7-4a75-ad0b-0fc6f1518994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 1117061\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:From <ipython-input-17-990fa0b65c86>:141: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/15\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.5277 - categorical_accuracy: 0.4314\n",
      "Epoch 00001: val_loss improved from inf to 1.43452, saving model to model_init_2021-06-2714_38_28.200764/model-00001-1.52767-0.43137-1.43452-0.43000.h5\n",
      "17/17 [==============================] - 123s 7s/step - loss: 1.5277 - categorical_accuracy: 0.4314 - val_loss: 1.4345 - val_categorical_accuracy: 0.4300\n",
      "Epoch 2/15\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8731 - categorical_accuracy: 0.6516\n",
      "Epoch 00002: val_loss did not improve from 1.43452\n",
      "17/17 [==============================] - 129s 8s/step - loss: 0.8731 - categorical_accuracy: 0.6516 - val_loss: 2.3116 - val_categorical_accuracy: 0.2200\n",
      "Epoch 3/15\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5614 - categorical_accuracy: 0.7858\n",
      "Epoch 00003: val_loss did not improve from 1.43452\n",
      "17/17 [==============================] - 121s 7s/step - loss: 0.5614 - categorical_accuracy: 0.7858 - val_loss: 3.0584 - val_categorical_accuracy: 0.2000\n",
      "Epoch 4/15\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4139 - categorical_accuracy: 0.8612\n",
      "Epoch 00004: val_loss did not improve from 1.43452\n",
      "17/17 [==============================] - 118s 7s/step - loss: 0.4139 - categorical_accuracy: 0.8612 - val_loss: 3.9495 - val_categorical_accuracy: 0.2100\n",
      "Epoch 5/15\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3466 - categorical_accuracy: 0.8854\n",
      "Epoch 00005: val_loss did not improve from 1.43452\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "17/17 [==============================] - 125s 7s/step - loss: 0.3466 - categorical_accuracy: 0.8854 - val_loss: 4.0541 - val_categorical_accuracy: 0.2200\n",
      "Epoch 6/15\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2196 - categorical_accuracy: 0.9306\n",
      "Epoch 00006: val_loss did not improve from 1.43452\n",
      "17/17 [==============================] - 124s 7s/step - loss: 0.2196 - categorical_accuracy: 0.9306 - val_loss: 4.3928 - val_categorical_accuracy: 0.1900\n",
      "Epoch 7/15\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1886 - categorical_accuracy: 0.9487\n",
      "Epoch 00007: val_loss did not improve from 1.43452\n",
      "17/17 [==============================] - 124s 7s/step - loss: 0.1886 - categorical_accuracy: 0.9487 - val_loss: 4.4589 - val_categorical_accuracy: 0.2100\n",
      "Epoch 8/15\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1730 - categorical_accuracy: 0.9563\n",
      "Epoch 00008: val_loss did not improve from 1.43452\n",
      "17/17 [==============================] - 119s 7s/step - loss: 0.1730 - categorical_accuracy: 0.9563 - val_loss: 5.2931 - val_categorical_accuracy: 0.1800\n",
      "Epoch 9/15\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1173 - categorical_accuracy: 0.9759\n",
      "Epoch 00009: val_loss did not improve from 1.43452\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "17/17 [==============================] - 122s 7s/step - loss: 0.1173 - categorical_accuracy: 0.9759 - val_loss: 4.6733 - val_categorical_accuracy: 0.2400\n",
      "Epoch 10/15\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1258 - categorical_accuracy: 0.9789\n",
      "Epoch 00010: val_loss did not improve from 1.43452\n",
      "17/17 [==============================] - 117s 7s/step - loss: 0.1258 - categorical_accuracy: 0.9789 - val_loss: 5.0375 - val_categorical_accuracy: 0.2100\n",
      "Epoch 11/15\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1208 - categorical_accuracy: 0.9759\n",
      "Epoch 00011: val_loss did not improve from 1.43452\n",
      "17/17 [==============================] - 120s 7s/step - loss: 0.1208 - categorical_accuracy: 0.9759 - val_loss: 5.2493 - val_categorical_accuracy: 0.1900\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "history_model1 = conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-toeTbCl0KV1"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-o_Jj9GrmKPC"
   },
   "outputs": [],
   "source": [
    "plot(history_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7V7ReJEVmKPC"
   },
   "source": [
    "##### Model is clearly overfitting. :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aucu7axXmKPD"
   },
   "source": [
    "## Model 2  \n",
    "### Adding dropout layers - Batch Size = 20 and No. of Epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "taBsVpLHmKPD",
    "outputId": "900b70a9-8e18-4029-a6b9-b3d4942f940f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_4 (Conv3D)            (None, 20, 160, 160, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 20, 160, 160, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 20, 160, 160, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 10, 80, 80, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 10, 80, 80, 32)    13856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10, 80, 80, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 10, 80, 80, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 5, 40, 40, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 5, 40, 40, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 5, 40, 40, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 5, 40, 40, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 2, 20, 20, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 2, 20, 20, 128)    221312    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2, 20, 20, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 2, 20, 20, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 1, 10, 10, 128)    0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               3277056   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 3,638,981\n",
      "Trainable params: 3,637,477\n",
      "Non-trainable params: 1,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d2=ModelConv3D1()\n",
    "conv_3d2.initialize_path(project_folder)\n",
    "conv_3d2.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d2.initialize_hyperparams(frames_to_sample=20,batch_size=20,num_epochs=25)\n",
    "conv_3d2_model=conv_3d2.define_model(dense_neurons=256,dropout=0.5)\n",
    "conv_3d2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "EkjN9FtzmKPD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3638981\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.9511 - categorical_accuracy: 0.3974\n",
      "Epoch 00001: val_loss improved from inf to 2.59632, saving model to model_init_2021-06-2715_01_07.112115/model-00001-1.95106-0.39744-2.59632-0.16000.h5\n",
      "34/34 [==============================] - 234s 7s/step - loss: 1.9511 - categorical_accuracy: 0.3974 - val_loss: 2.5963 - val_categorical_accuracy: 0.1600\n",
      "Epoch 2/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.3797 - categorical_accuracy: 0.5204\n",
      "Epoch 00002: val_loss did not improve from 2.59632\n",
      "34/34 [==============================] - 220s 6s/step - loss: 1.3797 - categorical_accuracy: 0.5204 - val_loss: 2.7610 - val_categorical_accuracy: 0.2000\n",
      "Epoch 3/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.1098 - categorical_accuracy: 0.6146\n",
      "Epoch 00003: val_loss did not improve from 2.59632\n",
      "34/34 [==============================] - 210s 6s/step - loss: 1.1098 - categorical_accuracy: 0.6146 - val_loss: 4.1400 - val_categorical_accuracy: 0.2500\n",
      "Epoch 4/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9436 - categorical_accuracy: 0.6606\n",
      "Epoch 00004: val_loss did not improve from 2.59632\n",
      "34/34 [==============================] - 220s 6s/step - loss: 0.9436 - categorical_accuracy: 0.6606 - val_loss: 4.4749 - val_categorical_accuracy: 0.1900\n",
      "Epoch 5/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7470 - categorical_accuracy: 0.7164\n",
      "Epoch 00005: val_loss did not improve from 2.59632\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "34/34 [==============================] - 214s 6s/step - loss: 0.7470 - categorical_accuracy: 0.7164 - val_loss: 4.6934 - val_categorical_accuracy: 0.2400\n",
      "Epoch 6/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5635 - categorical_accuracy: 0.7964\n",
      "Epoch 00006: val_loss did not improve from 2.59632\n",
      "34/34 [==============================] - 206s 6s/step - loss: 0.5635 - categorical_accuracy: 0.7964 - val_loss: 4.7243 - val_categorical_accuracy: 0.3100\n",
      "Epoch 7/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4672 - categorical_accuracy: 0.8228\n",
      "Epoch 00007: val_loss did not improve from 2.59632\n",
      "34/34 [==============================] - 213s 6s/step - loss: 0.4672 - categorical_accuracy: 0.8228 - val_loss: 4.2088 - val_categorical_accuracy: 0.2900\n",
      "Epoch 8/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4260 - categorical_accuracy: 0.8492\n",
      "Epoch 00008: val_loss did not improve from 2.59632\n",
      "34/34 [==============================] - 222s 7s/step - loss: 0.4260 - categorical_accuracy: 0.8492 - val_loss: 4.4966 - val_categorical_accuracy: 0.2400\n",
      "Epoch 9/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4019 - categorical_accuracy: 0.8499\n",
      "Epoch 00009: val_loss did not improve from 2.59632\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "34/34 [==============================] - 234s 7s/step - loss: 0.4019 - categorical_accuracy: 0.8499 - val_loss: 4.5160 - val_categorical_accuracy: 0.3100\n",
      "Epoch 10/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3387 - categorical_accuracy: 0.8884\n",
      "Epoch 00010: val_loss did not improve from 2.59632\n",
      "34/34 [==============================] - 228s 7s/step - loss: 0.3387 - categorical_accuracy: 0.8884 - val_loss: 4.1353 - val_categorical_accuracy: 0.3000\n",
      "Epoch 11/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3130 - categorical_accuracy: 0.8922\n",
      "Epoch 00011: val_loss did not improve from 2.59632\n",
      "34/34 [==============================] - 229s 7s/step - loss: 0.3130 - categorical_accuracy: 0.8922 - val_loss: 3.5891 - val_categorical_accuracy: 0.3100\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_3d2_model.count_params())\n",
    "history_model2=conv_3d2.train_model(conv_3d2_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-l6j_x6mKPE"
   },
   "source": [
    "##### We can see  val_loss did not improve from 1.24219 so earlystopping stops the epoch automatically!! \n",
    "- Last Epoch stop on 12/25!! good job earlystopping ;)\n",
    "- Best weights save automatically. The validation accuracy of 31% and training accuracy of 89%. Next we will try to reduce the filter size and image resolution and see if get better results. Moreover since we see minor oscillations  in loss, let's try lowering the learning rate to 0.0002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWw0zESomKPE"
   },
   "source": [
    "## Model 3 \n",
    "### Reduce filter size to (2,2,2) and image res to 120 x  120, - Batch Size = 30 and No. of Epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_eS7zJPRmKPF"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D3(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "        \n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6H1z3AKwmKPF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_8 (Conv3D)            (None, 16, 120, 120, 16)  400       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 8, 60, 60, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 8, 60, 60, 32)     4128      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 8, 60, 60, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8, 60, 60, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 4, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 4, 30, 30, 64)     16448     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4, 30, 30, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 2, 15, 15, 128)    65664     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 2, 15, 15, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 1, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,762,613\n",
      "Trainable params: 1,761,109\n",
      "Non-trainable params: 1,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d3=ModelConv3D3()\n",
    "conv_3d3.initialize_path(project_folder)\n",
    "conv_3d3.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d3.initialize_hyperparams(frames_to_sample=16,batch_size=30,num_epochs=25)\n",
    "conv_3d3_model=conv_3d3.define_model(filtersize=(2,2,2),dense_neurons=256,dropout=0.5)\n",
    "conv_3d3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "PUhnqc9imKPG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 1762613\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 2.0443 - categorical_accuracy: 0.3552\n",
      "Epoch 00001: val_loss improved from inf to 1.94308, saving model to model_init_2021-06-2715_44_02.585483/model-00001-2.04427-0.35520-1.94308-0.16000.h5\n",
      "23/23 [==============================] - 157s 7s/step - loss: 2.0443 - categorical_accuracy: 0.3552 - val_loss: 1.9431 - val_categorical_accuracy: 0.1600\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.4391 - categorical_accuracy: 0.5000\n",
      "Epoch 00002: val_loss did not improve from 1.94308\n",
      "23/23 [==============================] - 169s 7s/step - loss: 1.4391 - categorical_accuracy: 0.5000 - val_loss: 2.9049 - val_categorical_accuracy: 0.1800\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.2598 - categorical_accuracy: 0.5543\n",
      "Epoch 00003: val_loss did not improve from 1.94308\n",
      "23/23 [==============================] - 156s 7s/step - loss: 1.2598 - categorical_accuracy: 0.5543 - val_loss: 3.5751 - val_categorical_accuracy: 0.1700\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.1444 - categorical_accuracy: 0.6003\n",
      "Epoch 00004: val_loss did not improve from 1.94308\n",
      "23/23 [==============================] - 150s 7s/step - loss: 1.1444 - categorical_accuracy: 0.6003 - val_loss: 4.4440 - val_categorical_accuracy: 0.1800\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.0089 - categorical_accuracy: 0.6425\n",
      "Epoch 00005: val_loss did not improve from 1.94308\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n",
      "23/23 [==============================] - 159s 7s/step - loss: 1.0089 - categorical_accuracy: 0.6425 - val_loss: 5.1340 - val_categorical_accuracy: 0.1600\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.9077 - categorical_accuracy: 0.6704\n",
      "Epoch 00006: val_loss did not improve from 1.94308\n",
      "23/23 [==============================] - 155s 7s/step - loss: 0.9077 - categorical_accuracy: 0.6704 - val_loss: 5.7406 - val_categorical_accuracy: 0.1900\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.8619 - categorical_accuracy: 0.6900\n",
      "Epoch 00007: val_loss did not improve from 1.94308\n",
      "23/23 [==============================] - 155s 7s/step - loss: 0.8619 - categorical_accuracy: 0.6900 - val_loss: 5.9235 - val_categorical_accuracy: 0.2600\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.8597 - categorical_accuracy: 0.6938\n",
      "Epoch 00008: val_loss did not improve from 1.94308\n",
      "23/23 [==============================] - 152s 7s/step - loss: 0.8597 - categorical_accuracy: 0.6938 - val_loss: 6.3905 - val_categorical_accuracy: 0.2500\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.8932 - categorical_accuracy: 0.6817\n",
      "Epoch 00009: val_loss did not improve from 1.94308\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n",
      "23/23 [==============================] - 151s 7s/step - loss: 0.8932 - categorical_accuracy: 0.6817 - val_loss: 6.6415 - val_categorical_accuracy: 0.2200\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.8155 - categorical_accuracy: 0.6983\n",
      "Epoch 00010: val_loss did not improve from 1.94308\n",
      "23/23 [==============================] - 153s 7s/step - loss: 0.8155 - categorical_accuracy: 0.6983 - val_loss: 6.7608 - val_categorical_accuracy: 0.2700\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.7660 - categorical_accuracy: 0.7066\n",
      "Epoch 00011: val_loss did not improve from 1.94308\n",
      "23/23 [==============================] - 153s 7s/step - loss: 0.7660 - categorical_accuracy: 0.7066 - val_loss: 6.2631 - val_categorical_accuracy: 0.2200\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_3d3_model.count_params())\n",
    "history_model3=conv_3d3.train_model(conv_3d3_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBbuRQv0mKPG"
   },
   "outputs": [],
   "source": [
    "plot(history_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H36KgwIomKPG"
   },
   "source": [
    "##### Model has a validation accuracy of 22% and training accuracy of 76% . Also we were able to reduce the parameter size by half the earlier model. Let's trying adding more layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22tTFodkmKPH"
   },
   "source": [
    "## Model 4 - \n",
    "### Adding more layers - Batch Size = 20 and No. of Epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "DZY6l13wmKPH"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D4(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "AV-oHSgumKPI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_12 (Conv3D)           (None, 16, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 16, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 16, 120, 120, 16)  6928      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 16, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 8, 60, 60, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 8, 60, 60, 32)     13856     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 8, 60, 60, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 8, 60, 60, 32)     128       \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 8, 60, 60, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 8, 60, 60, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 8, 60, 60, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling (None, 4, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_16 (Conv3D)           (None, 4, 30, 30, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 4, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 4, 30, 30, 64)     256       \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 4, 30, 30, 64)     110656    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 4, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 4, 30, 30, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_18 (Conv3D)           (None, 2, 15, 15, 128)    221312    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 2, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 2, 15, 15, 128)    512       \n",
      "_________________________________________________________________\n",
      "conv3d_19 (Conv3D)           (None, 2, 15, 15, 128)    442496    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 2, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 2, 15, 15, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 1, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 2,556,533\n",
      "Trainable params: 2,554,549\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d4=ModelConv3D4()\n",
    "conv_3d4.initialize_path(project_folder)\n",
    "conv_3d4.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d4.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
    "conv_3d4_model=conv_3d4.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.5)\n",
    "conv_3d4_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "MWgKSyd4mKPI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 2556533\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.0113 - categorical_accuracy: 0.3771\n",
      "Epoch 00001: val_loss improved from inf to 2.07433, saving model to model_init_2021-06-2716_20_27.733289/model-00001-2.01130-0.37707-2.07433-0.32000.h5\n",
      "34/34 [==============================] - 146s 4s/step - loss: 2.0113 - categorical_accuracy: 0.3771 - val_loss: 2.0743 - val_categorical_accuracy: 0.3200\n",
      "Epoch 2/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.6188 - categorical_accuracy: 0.4623\n",
      "Epoch 00002: val_loss did not improve from 2.07433\n",
      "34/34 [==============================] - 143s 4s/step - loss: 1.6188 - categorical_accuracy: 0.4623 - val_loss: 2.7347 - val_categorical_accuracy: 0.2100\n",
      "Epoch 3/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.4337 - categorical_accuracy: 0.5121\n",
      "Epoch 00003: val_loss did not improve from 2.07433\n",
      "34/34 [==============================] - 148s 4s/step - loss: 1.4337 - categorical_accuracy: 0.5121 - val_loss: 2.3617 - val_categorical_accuracy: 0.2100\n",
      "Epoch 4/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.2037 - categorical_accuracy: 0.5603\n",
      "Epoch 00004: val_loss did not improve from 2.07433\n",
      "34/34 [==============================] - 157s 5s/step - loss: 1.2037 - categorical_accuracy: 0.5603 - val_loss: 2.8389 - val_categorical_accuracy: 0.2500\n",
      "Epoch 5/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0812 - categorical_accuracy: 0.6327\n",
      "Epoch 00005: val_loss did not improve from 2.07433\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "34/34 [==============================] - 153s 4s/step - loss: 1.0812 - categorical_accuracy: 0.6327 - val_loss: 2.2230 - val_categorical_accuracy: 0.2500\n",
      "Epoch 6/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9258 - categorical_accuracy: 0.6659\n",
      "Epoch 00006: val_loss did not improve from 2.07433\n",
      "34/34 [==============================] - 147s 4s/step - loss: 0.9258 - categorical_accuracy: 0.6659 - val_loss: 2.8821 - val_categorical_accuracy: 0.2400\n",
      "Epoch 7/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7818 - categorical_accuracy: 0.7119\n",
      "Epoch 00007: val_loss did not improve from 2.07433\n",
      "34/34 [==============================] - 144s 4s/step - loss: 0.7818 - categorical_accuracy: 0.7119 - val_loss: 2.9437 - val_categorical_accuracy: 0.2400\n",
      "Epoch 8/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7755 - categorical_accuracy: 0.7119\n",
      "Epoch 00008: val_loss did not improve from 2.07433\n",
      "34/34 [==============================] - 153s 4s/step - loss: 0.7755 - categorical_accuracy: 0.7119 - val_loss: 3.5735 - val_categorical_accuracy: 0.1900\n",
      "Epoch 9/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7504 - categorical_accuracy: 0.7262\n",
      "Epoch 00009: val_loss did not improve from 2.07433\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "34/34 [==============================] - 146s 4s/step - loss: 0.7504 - categorical_accuracy: 0.7262 - val_loss: 2.5899 - val_categorical_accuracy: 0.3600\n",
      "Epoch 10/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6440 - categorical_accuracy: 0.7670\n",
      "Epoch 00010: val_loss did not improve from 2.07433\n",
      "34/34 [==============================] - 145s 4s/step - loss: 0.6440 - categorical_accuracy: 0.7670 - val_loss: 2.4155 - val_categorical_accuracy: 0.3500\n",
      "Epoch 11/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6362 - categorical_accuracy: 0.7557\n",
      "Epoch 00011: val_loss did not improve from 2.07433\n",
      "34/34 [==============================] - 149s 4s/step - loss: 0.6362 - categorical_accuracy: 0.7557 - val_loss: 2.4547 - val_categorical_accuracy: 0.3300\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_3d4_model.count_params())\n",
    "history_model4=conv_3d4.train_model(conv_3d4_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfSV6xwqmKPI"
   },
   "outputs": [],
   "source": [
    "plot(history_model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUQ8Sv7wmKPJ"
   },
   "source": [
    "##### With more layers we dont see much performance improvement. We get a best validation accuracy of 76% . Let's try adding dropouts at the convolution layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UK6DUV_8mKPJ"
   },
   "source": [
    "## Model 5 \n",
    "### Adding dropout at convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "laG2842BmKPJ"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D5(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "nIcvunkTmKPK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_20 (Conv3D)           (None, 16, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 16, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 16, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "conv3d_21 (Conv3D)           (None, 16, 120, 120, 16)  6928      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 16, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 8, 60, 60, 16)     0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 8, 60, 60, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_22 (Conv3D)           (None, 8, 60, 60, 32)     13856     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 8, 60, 60, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 8, 60, 60, 32)     128       \n",
      "_________________________________________________________________\n",
      "conv3d_23 (Conv3D)           (None, 8, 60, 60, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 8, 60, 60, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 8, 60, 60, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 4, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_24 (Conv3D)           (None, 4, 30, 30, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 4, 30, 30, 64)     256       \n",
      "_________________________________________________________________\n",
      "conv3d_25 (Conv3D)           (None, 4, 30, 30, 64)     110656    \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 4, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 4, 30, 30, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_26 (Conv3D)           (None, 2, 15, 15, 128)    221312    \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 2, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 2, 15, 15, 128)    512       \n",
      "_________________________________________________________________\n",
      "conv3d_27 (Conv3D)           (None, 2, 15, 15, 128)    442496    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 2, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 2, 15, 15, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_19 (MaxPooling (None, 1, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 2,556,533\n",
      "Trainable params: 2,554,549\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d5=ModelConv3D5()\n",
    "conv_3d5.initialize_path(project_folder)\n",
    "conv_3d5.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d5.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=15)\n",
    "conv_3d5_model=conv_3d5.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.25)\n",
    "conv_3d5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "OyuLB6N6mKPK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 2556533\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.6748 - categorical_accuracy: 0.4321\n",
      "Epoch 00001: val_loss improved from inf to 2.65023, saving model to model_init_2021-06-2716_47_52.782867/model-00001-1.67481-0.43213-2.65023-0.21000.h5\n",
      "34/34 [==============================] - 146s 4s/step - loss: 1.6748 - categorical_accuracy: 0.4321 - val_loss: 2.6502 - val_categorical_accuracy: 0.2100\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.2031 - categorical_accuracy: 0.5407\n",
      "Epoch 00002: val_loss did not improve from 2.65023\n",
      "34/34 [==============================] - 146s 4s/step - loss: 1.2031 - categorical_accuracy: 0.5407 - val_loss: 2.7056 - val_categorical_accuracy: 0.1900\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0529 - categorical_accuracy: 0.6267\n",
      "Epoch 00003: val_loss did not improve from 2.65023\n",
      "34/34 [==============================] - 145s 4s/step - loss: 1.0529 - categorical_accuracy: 0.6267 - val_loss: 3.4243 - val_categorical_accuracy: 0.1800\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0229 - categorical_accuracy: 0.6282\n",
      "Epoch 00004: val_loss did not improve from 2.65023\n",
      "34/34 [==============================] - 150s 4s/step - loss: 1.0229 - categorical_accuracy: 0.6282 - val_loss: 3.6055 - val_categorical_accuracy: 0.1800\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.8521 - categorical_accuracy: 0.6863\n",
      "Epoch 00005: val_loss did not improve from 2.65023\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "34/34 [==============================] - 153s 5s/step - loss: 0.8521 - categorical_accuracy: 0.6863 - val_loss: 3.1174 - val_categorical_accuracy: 0.2300\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6462 - categorical_accuracy: 0.7481\n",
      "Epoch 00006: val_loss did not improve from 2.65023\n",
      "34/34 [==============================] - 146s 4s/step - loss: 0.6462 - categorical_accuracy: 0.7481 - val_loss: 3.4630 - val_categorical_accuracy: 0.2100\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5193 - categorical_accuracy: 0.8024\n",
      "Epoch 00007: val_loss did not improve from 2.65023\n",
      "34/34 [==============================] - 155s 5s/step - loss: 0.5193 - categorical_accuracy: 0.8024 - val_loss: 4.2096 - val_categorical_accuracy: 0.1900\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5165 - categorical_accuracy: 0.8130\n",
      "Epoch 00008: val_loss did not improve from 2.65023\n",
      "34/34 [==============================] - 149s 4s/step - loss: 0.5165 - categorical_accuracy: 0.8130 - val_loss: 3.8293 - val_categorical_accuracy: 0.2100\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4968 - categorical_accuracy: 0.8069\n",
      "Epoch 00009: val_loss did not improve from 2.65023\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "34/34 [==============================] - 148s 4s/step - loss: 0.4968 - categorical_accuracy: 0.8069 - val_loss: 3.9952 - val_categorical_accuracy: 0.2700\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3959 - categorical_accuracy: 0.8507\n",
      "Epoch 00010: val_loss did not improve from 2.65023\n",
      "34/34 [==============================] - 146s 4s/step - loss: 0.3959 - categorical_accuracy: 0.8507 - val_loss: 3.9740 - val_categorical_accuracy: 0.2400\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3765 - categorical_accuracy: 0.8469\n",
      "Epoch 00011: val_loss did not improve from 2.65023\n",
      "34/34 [==============================] - 147s 4s/step - loss: 0.3765 - categorical_accuracy: 0.8469 - val_loss: 3.7196 - val_categorical_accuracy: 0.2700\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_3d5_model.count_params())\n",
    "history_model5=conv_3d5.train_model(conv_3d5_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iu4zC8VSmKPL"
   },
   "outputs": [],
   "source": [
    "plot(history_model5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEChg3_jmKPL"
   },
   "source": [
    " __Ohh! Overfitting again!! Adding dropouts has further reduced validation accuracy as the model doesn't seem to generalise well.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGgKDxvHmKPL"
   },
   "source": [
    "##### All the experimental models above have more than 1 million parameters. Let's try to reduce the model size and see the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov3RbhgcmKPM"
   },
   "source": [
    "## Model 6 \n",
    "### Reducing the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dbOJrWRhmKPM"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D6(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "XLGq3sXimKPN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_28 (Conv3D)           (None, 16, 100, 100, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16, 100, 100, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 16, 100, 100, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_20 (MaxPooling (None, 8, 50, 50, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_29 (Conv3D)           (None, 8, 50, 50, 32)     4128      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 8, 50, 50, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 8, 50, 50, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_21 (MaxPooling (None, 4, 25, 25, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_30 (Conv3D)           (None, 4, 25, 25, 64)     16448     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 4, 25, 25, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 4, 25, 25, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_22 (MaxPooling (None, 2, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_31 (Conv3D)           (None, 2, 12, 12, 128)    65664     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 2, 12, 12, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 2, 12, 12, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_23 (MaxPooling (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 696,645\n",
      "Trainable params: 695,653\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d6=ModelConv3D6()\n",
    "conv_3d6.initialize_path(project_folder)\n",
    "conv_3d6.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d6.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=20)\n",
    "conv_3d6_model=conv_3d6.define_model(dense_neurons=128,dropout=0.25)\n",
    "conv_3d6_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "i_aBVZ9QmKPN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 696645\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7133 - categorical_accuracy: 0.3831\n",
      "Epoch 00001: val_loss improved from inf to 2.18368, saving model to model_init_2021-06-2717_15_15.960823/model-00001-1.71327-0.38311-2.18368-0.21000.h5\n",
      "34/34 [==============================] - 148s 4s/step - loss: 1.7133 - categorical_accuracy: 0.3831 - val_loss: 2.1837 - val_categorical_accuracy: 0.2100\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0836 - categorical_accuracy: 0.5807\n",
      "Epoch 00002: val_loss did not improve from 2.18368\n",
      "34/34 [==============================] - 154s 5s/step - loss: 1.0836 - categorical_accuracy: 0.5807 - val_loss: 3.8183 - val_categorical_accuracy: 0.2400\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9123 - categorical_accuracy: 0.6554\n",
      "Epoch 00003: val_loss did not improve from 2.18368\n",
      "34/34 [==============================] - 152s 4s/step - loss: 0.9123 - categorical_accuracy: 0.6554 - val_loss: 5.3706 - val_categorical_accuracy: 0.1700\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7566 - categorical_accuracy: 0.7157\n",
      "Epoch 00004: val_loss did not improve from 2.18368\n",
      "34/34 [==============================] - 141s 4s/step - loss: 0.7566 - categorical_accuracy: 0.7157 - val_loss: 6.5694 - val_categorical_accuracy: 0.2300\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6754 - categorical_accuracy: 0.7534\n",
      "Epoch 00005: val_loss did not improve from 2.18368\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n",
      "34/34 [==============================] - 142s 4s/step - loss: 0.6754 - categorical_accuracy: 0.7534 - val_loss: 7.5768 - val_categorical_accuracy: 0.2200\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5559 - categorical_accuracy: 0.7881\n",
      "Epoch 00006: val_loss did not improve from 2.18368\n",
      "34/34 [==============================] - 139s 4s/step - loss: 0.5559 - categorical_accuracy: 0.7881 - val_loss: 7.8106 - val_categorical_accuracy: 0.2100\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5403 - categorical_accuracy: 0.7964\n",
      "Epoch 00007: val_loss did not improve from 2.18368\n",
      "34/34 [==============================] - 147s 4s/step - loss: 0.5403 - categorical_accuracy: 0.7964 - val_loss: 7.2173 - val_categorical_accuracy: 0.2500\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5028 - categorical_accuracy: 0.8228\n",
      "Epoch 00008: val_loss did not improve from 2.18368\n",
      "34/34 [==============================] - 144s 4s/step - loss: 0.5028 - categorical_accuracy: 0.8228 - val_loss: 7.8080 - val_categorical_accuracy: 0.1400\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4945 - categorical_accuracy: 0.8137\n",
      "Epoch 00009: val_loss did not improve from 2.18368\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n",
      "34/34 [==============================] - 145s 4s/step - loss: 0.4945 - categorical_accuracy: 0.8137 - val_loss: 5.7403 - val_categorical_accuracy: 0.2200\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4651 - categorical_accuracy: 0.8341\n",
      "Epoch 00010: val_loss did not improve from 2.18368\n",
      "34/34 [==============================] - 148s 4s/step - loss: 0.4651 - categorical_accuracy: 0.8341 - val_loss: 5.1623 - val_categorical_accuracy: 0.2000\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4793 - categorical_accuracy: 0.8333\n",
      "Epoch 00011: val_loss did not improve from 2.18368\n",
      "34/34 [==============================] - 146s 4s/step - loss: 0.4793 - categorical_accuracy: 0.8333 - val_loss: 4.3393 - val_categorical_accuracy: 0.2200\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_3d6_model.count_params())\n",
    "history_model6=conv_3d6.train_model(conv_3d6_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLYait97mKPN"
   },
   "outputs": [],
   "source": [
    "plot(history_model6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpUL_6Q7mKPO"
   },
   "source": [
    "###### For the above low memory foot print model, we get the best validation accuracy of 74%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAFjyE5TmKPO"
   },
   "source": [
    "## Model 7 - Reducing the number of parameters again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "95SIDiuWmKPO"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D7(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, (3, 3, 3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "5u70d3SzmKPP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_32 (Conv3D)           (None, 16, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 16, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 16, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_24 (MaxPooling (None, 8, 60, 60, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_33 (Conv3D)           (None, 8, 60, 60, 32)     13856     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 8, 60, 60, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 8, 60, 60, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_25 (MaxPooling (None, 4, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_34 (Conv3D)           (None, 4, 30, 30, 64)     16448     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 4, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 4, 30, 30, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_26 (MaxPooling (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_35 (Conv3D)           (None, 2, 15, 15, 128)    65664     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 2, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 2, 15, 15, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_27 (MaxPooling (None, 1, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                401472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 504,709\n",
      "Trainable params: 503,973\n",
      "Non-trainable params: 736\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d7=ModelConv3D7()\n",
    "conv_3d7.initialize_path(project_folder)\n",
    "conv_3d7.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d7.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
    "conv_3d7_model=conv_3d7.define_model(dense_neurons=64,dropout=0.25)\n",
    "conv_3d7_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "gBX-IXXQmKPP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 504709\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7395 - categorical_accuracy: 0.3431\n",
      "Epoch 00001: val_loss improved from inf to 1.72494, saving model to model_init_2021-06-2717_42_08.423717/model-00001-1.73951-0.34314-1.72494-0.21000.h5\n",
      "34/34 [==============================] - 147s 4s/step - loss: 1.7395 - categorical_accuracy: 0.3431 - val_loss: 1.7249 - val_categorical_accuracy: 0.2100\n",
      "Epoch 2/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.2508 - categorical_accuracy: 0.5181\n",
      "Epoch 00002: val_loss did not improve from 1.72494\n",
      "34/34 [==============================] - 151s 4s/step - loss: 1.2508 - categorical_accuracy: 0.5181 - val_loss: 1.9746 - val_categorical_accuracy: 0.1900\n",
      "Epoch 3/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0488 - categorical_accuracy: 0.5935\n",
      "Epoch 00003: val_loss did not improve from 1.72494\n",
      "34/34 [==============================] - 145s 4s/step - loss: 1.0488 - categorical_accuracy: 0.5935 - val_loss: 2.2894 - val_categorical_accuracy: 0.2400\n",
      "Epoch 4/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9516 - categorical_accuracy: 0.6320\n",
      "Epoch 00004: val_loss did not improve from 1.72494\n",
      "34/34 [==============================] - 146s 4s/step - loss: 0.9516 - categorical_accuracy: 0.6320 - val_loss: 2.8779 - val_categorical_accuracy: 0.1900\n",
      "Epoch 5/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7994 - categorical_accuracy: 0.6908\n",
      "Epoch 00005: val_loss did not improve from 1.72494\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n",
      "34/34 [==============================] - 144s 4s/step - loss: 0.7994 - categorical_accuracy: 0.6908 - val_loss: 3.1850 - val_categorical_accuracy: 0.2300\n",
      "Epoch 6/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6904 - categorical_accuracy: 0.7391\n",
      "Epoch 00006: val_loss did not improve from 1.72494\n",
      "34/34 [==============================] - 147s 4s/step - loss: 0.6904 - categorical_accuracy: 0.7391 - val_loss: 3.5937 - val_categorical_accuracy: 0.2100\n",
      "Epoch 7/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7010 - categorical_accuracy: 0.7413\n",
      "Epoch 00007: val_loss did not improve from 1.72494\n",
      "34/34 [==============================] - 148s 4s/step - loss: 0.7010 - categorical_accuracy: 0.7413 - val_loss: 3.6294 - val_categorical_accuracy: 0.2600\n",
      "Epoch 8/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6674 - categorical_accuracy: 0.7541\n",
      "Epoch 00008: val_loss did not improve from 1.72494\n",
      "34/34 [==============================] - 147s 4s/step - loss: 0.6674 - categorical_accuracy: 0.7541 - val_loss: 3.9465 - val_categorical_accuracy: 0.2700\n",
      "Epoch 9/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6767 - categorical_accuracy: 0.7481\n",
      "Epoch 00009: val_loss did not improve from 1.72494\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n",
      "34/34 [==============================] - 143s 4s/step - loss: 0.6767 - categorical_accuracy: 0.7481 - val_loss: 4.1960 - val_categorical_accuracy: 0.2500\n",
      "Epoch 10/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6586 - categorical_accuracy: 0.7572\n",
      "Epoch 00010: val_loss did not improve from 1.72494\n",
      "34/34 [==============================] - 144s 4s/step - loss: 0.6586 - categorical_accuracy: 0.7572 - val_loss: 3.7135 - val_categorical_accuracy: 0.2800\n",
      "Epoch 11/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6100 - categorical_accuracy: 0.7790\n",
      "Epoch 00011: val_loss did not improve from 1.72494\n",
      "34/34 [==============================] - 141s 4s/step - loss: 0.6100 - categorical_accuracy: 0.7790 - val_loss: 3.6006 - val_categorical_accuracy: 0.2700\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_3d7_model.count_params())\n",
    "history_model7=conv_3d7.train_model(conv_3d7_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wm5_hHZymKPP"
   },
   "outputs": [],
   "source": [
    "plot(history_model7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBAcznCwmKPQ"
   },
   "source": [
    "###### For the above low memory foot print model the best validation accuracy of 73%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-kbPx90mKPQ"
   },
   "source": [
    "## Model 8 - CNN- LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "qZY_cLOpmKPQ"
   },
   "outputs": [],
   "source": [
    "class RNNCNN1(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
    "                                  input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(256, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        #model.add(TimeDistributed(Conv2D(512, (2, 2) , padding='valid', activation='relu')))\n",
    "       # model.add(TimeDistributed(BatchNormalization()))\n",
    "       # model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "        model.add(LSTM(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ISrWU7IRmKPR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 18, 120, 120, 16)  448       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 18, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 18, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 18, 60, 60, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 18, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 18, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 18, 30, 30, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 18, 30, 30, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 18, 15, 15, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 18, 15, 15, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 18, 15, 15, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 18, 7, 7, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 18, 7, 7, 256)     295168    \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 18, 7, 7, 256)     1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 18, 3, 3, 256)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 18, 2304)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               1245696   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,657,445\n",
      "Trainable params: 1,656,453\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_cnn1=RNNCNN1()\n",
    "rnn_cnn1.initialize_path(project_folder)\n",
    "rnn_cnn1.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn1.initialize_hyperparams(frames_to_sample=18,batch_size=20,num_epochs=20)\n",
    "rnn_cnn1_model=rnn_cnn1.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "LrvS52ntmKPR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 1657445\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:From <ipython-input-14-990fa0b65c86>:141: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.3203 - categorical_accuracy: 0.4374\n",
      "Epoch 00001: val_loss improved from inf to 1.72564, saving model to model_init_2021-06-2718_56_59.265745/model-00001-1.32031-0.43741-1.72564-0.21000.h5\n",
      "34/34 [==============================] - 160s 5s/step - loss: 1.3203 - categorical_accuracy: 0.4374 - val_loss: 1.7256 - val_categorical_accuracy: 0.2100\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0461 - categorical_accuracy: 0.5882\n",
      "Epoch 00002: val_loss did not improve from 1.72564\n",
      "34/34 [==============================] - 162s 5s/step - loss: 1.0461 - categorical_accuracy: 0.5882 - val_loss: 2.2362 - val_categorical_accuracy: 0.2500\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.8543 - categorical_accuracy: 0.6614\n",
      "Epoch 00003: val_loss did not improve from 1.72564\n",
      "34/34 [==============================] - 159s 5s/step - loss: 0.8543 - categorical_accuracy: 0.6614 - val_loss: 2.1662 - val_categorical_accuracy: 0.1800\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.8109 - categorical_accuracy: 0.6953\n",
      "Epoch 00004: val_loss did not improve from 1.72564\n",
      "34/34 [==============================] - 159s 5s/step - loss: 0.8109 - categorical_accuracy: 0.6953 - val_loss: 3.2859 - val_categorical_accuracy: 0.2300\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7158 - categorical_accuracy: 0.7436\n",
      "Epoch 00005: val_loss did not improve from 1.72564\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "34/34 [==============================] - 159s 5s/step - loss: 0.7158 - categorical_accuracy: 0.7436 - val_loss: 2.0320 - val_categorical_accuracy: 0.2500\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5956 - categorical_accuracy: 0.7896\n",
      "Epoch 00006: val_loss did not improve from 1.72564\n",
      "34/34 [==============================] - 162s 5s/step - loss: 0.5956 - categorical_accuracy: 0.7896 - val_loss: 2.1474 - val_categorical_accuracy: 0.2200\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4795 - categorical_accuracy: 0.8318\n",
      "Epoch 00007: val_loss did not improve from 1.72564\n",
      "34/34 [==============================] - 163s 5s/step - loss: 0.4795 - categorical_accuracy: 0.8318 - val_loss: 2.4351 - val_categorical_accuracy: 0.2100\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4334 - categorical_accuracy: 0.8454\n",
      "Epoch 00008: val_loss did not improve from 1.72564\n",
      "34/34 [==============================] - 169s 5s/step - loss: 0.4334 - categorical_accuracy: 0.8454 - val_loss: 2.1270 - val_categorical_accuracy: 0.2700\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3907 - categorical_accuracy: 0.8703\n",
      "Epoch 00009: val_loss did not improve from 1.72564\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "34/34 [==============================] - 165s 5s/step - loss: 0.3907 - categorical_accuracy: 0.8703 - val_loss: 2.2391 - val_categorical_accuracy: 0.2400\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3138 - categorical_accuracy: 0.9042\n",
      "Epoch 00010: val_loss did not improve from 1.72564\n",
      "34/34 [==============================] - 164s 5s/step - loss: 0.3138 - categorical_accuracy: 0.9042 - val_loss: 2.1951 - val_categorical_accuracy: 0.2900\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3328 - categorical_accuracy: 0.8944\n",
      "Epoch 00011: val_loss did not improve from 1.72564\n",
      "34/34 [==============================] - 164s 5s/step - loss: 0.3328 - categorical_accuracy: 0.8944 - val_loss: 2.0754 - val_categorical_accuracy: 0.3700\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", rnn_cnn1_model.count_params())\n",
    "history_model8=rnn_cnn1.train_model(rnn_cnn1_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjG23o_emKPR"
   },
   "outputs": [],
   "source": [
    "plot(history_model8)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "Gesture_Recognition_26th june_saturday.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
